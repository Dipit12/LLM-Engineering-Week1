{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# URL Summarization using Ollama\n",
        "\n",
        "This notebook demonstrates how to use Ollama (local LLM) to summarize content from a URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from ollama import chat\n",
        "from ollama import ChatResponse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Extract text content from a URL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_from_url(url):\n",
        "    \"\"\"\n",
        "    Fetches a webpage and extracts all text content from it.\n",
        "    \n",
        "    Args:\n",
        "        url (str): The URL of the webpage to extract text from\n",
        "        \n",
        "    Returns:\n",
        "        str: The extracted text content from the webpage\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        return soup.get_text()\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching URL: {e}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Summarize content using Ollama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_url(url, model='gemma3', max_words=100):\n",
        "    \"\"\"\n",
        "    Extracts text from a URL and summarizes it using a local LLM via Ollama.\n",
        "    \n",
        "    Args:\n",
        "        url (str): The URL of the webpage to summarize\n",
        "        model (str): The Ollama model to use (default: 'gemma3')\n",
        "        max_words (int): Maximum number of words for the summary (default: 100)\n",
        "        \n",
        "    Returns:\n",
        "        str: The summary of the webpage content\n",
        "    \"\"\"\n",
        "    # Extract text content from URL\n",
        "    text_content = extract_text_from_url(url)\n",
        "    \n",
        "    # Truncate content if it's too long (to avoid token limits)\n",
        "    # Most models have context limits, so we'll limit to first 5000 characters\n",
        "    if len(text_content) > 5000:\n",
        "        text_content = text_content[:5000] + \"... [content truncated]\"\n",
        "    \n",
        "    # Create prompt for summarization\n",
        "    prompt = f\"Please summarize the following text in approximately {max_words} words:\\n\\n{text_content}\"\n",
        "    \n",
        "    # Call Ollama API\n",
        "    messages = [\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': prompt\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    response: ChatResponse = chat(model=model, messages=messages)\n",
        "    return response.message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Test the solution\n",
        "\n",
        "Let's test the URL summarization function with an example URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Summarize a webpage\n",
        "url = \"https://www.geeksforgeeks.org/dsa/introduction-to-arrays-data-structure-and-algorithm-tutorials/\"\n",
        "\n",
        "print(\"Extracting and summarizing content from:\", url)\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "summary = summarize_url(url, model='gemma3', max_words=100)\n",
        "print(\"Summary:\")\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
