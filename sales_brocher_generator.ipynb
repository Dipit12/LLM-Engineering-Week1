{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7ce16e",
   "metadata": {},
   "source": [
    "## Company Sales Brochure Generator\n",
    "\n",
    "- Create a product that can generate marketing brochures about a company\n",
    "    - For prospective clients\n",
    "    - For investors\n",
    "    - For recruitment\n",
    "\n",
    "- The Technology\n",
    "    - Use Grok API/ OpenAI API\n",
    "    - Use one-shot prompting\n",
    "    - Stream back results and show with formatting\n",
    "- We will be provided a company name and their primary website.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3769501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will make the imports here\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from groq import Groq\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found api key we are good to go\n"
     ]
    }
   ],
   "source": [
    "# fetch the API from the env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"API key not found\")\n",
    "    raise ValueError(\"API key not present in env fiel\")\n",
    "else:\n",
    "    print(\"Found api key we are good to go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ae7058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome - Edward Donner\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHomeConnect FourOutsmartAn arena that pits LLMs against each other in a battle of diplomacy and deviousnessAboutPosts\\n\\n\\n\\n\\n\\n\\n\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (very amateur) and losing myself in Hacker News, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of Nebula.io. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt, acquired in 2021.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve patented our matching model, and our award-winning platform has happy customers and tons of press coverage. Connect with me for more!\\n\\n\\n\\nNovember 11, 2025\\nThe Unique Energy of an AI Live Event\\n\\n\\nSeptember 15, 2025\\nAI in Production: Gen AI and Agentic AI on AWS at scale\\n\\n\\nMay 28, 2025\\nBe an AI Engineer and Leader: The Curriculum\\n\\n\\nMay 18, 2025\\n2025 AI Executive Briefing\\n\\n\\n\\n\\n\\n\\n\\nNavigation\\nHomeConnect FourOutsmartAn arena that pits LLMs against each other in a battle of diplomacy and deviousnessAboutPosts\\n\\nGet in touch\\n\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\n\\n\\n\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\n\\n\\nSubscribe to newsletter\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tType your email…\\t\\t\\t\\t\\t\\t\\t\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\tSubscribe\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will be given an URL and we need to fetch the content of that website also we need to scrape all the links present in the webpage\n",
    "# then we need to create another function which would give us the relevant links\n",
    "\n",
    "def getContentOfWebPage(url):\n",
    "    response = requests.get(url)\n",
    "    content_of_webpage = BeautifulSoup(response.text,'html.parser')\n",
    "    return content_of_webpage.get_text()\n",
    "\n",
    "getContentOfWebPage(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2103f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/11/11/ai-live-event/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAllLinksFromAWebPage(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    # initialise an empty list\n",
    "    list_of_tags = []\n",
    "    for link in soup.find_all('a'):\n",
    "        list_of_tags.append(link.get('href'))\n",
    "    \n",
    "    return list_of_tags\n",
    "\n",
    "getAllLinksFromAWebPage(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"links\": [\\n        {\"type\": \"about page\", \"url\": \"https://edwarddonner.com/about-me-and-about-nebula/\"},\\n        {\"type\": \"company website\", \"url\": \"https://edwarddonner.com/\"},\\n        {\"type\": \"linkedin profile\", \"url\": \"https://www.linkedin.com/in/eddonner/\"},\\n        {\"type\": \"twitter profile\", \"url\": \"https://twitter.com/edwarddonner\"},\\n        {\"type\": \"facebook profile\", \"url\": \"https://www.facebook.com/edward.donner.52\"}\\n    ]\\n}\\n```'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an function that finds all the relevant tags\n",
    "client = Groq(api_key=api_key)\n",
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = getAllLinksFromAWebPage(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt\n",
    "\n",
    "def extractAllRelevantTags(url):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"llama-3.3-70b-versatile\",\n",
    "        messages= [\n",
    "            {\"role\":\"system\", \"content\":f\"{link_system_prompt}\"},\n",
    "            {\"role\":\"user\", \"content\":get_links_user_prompt(url)}\n",
    "        ]\n",
    "    )\n",
    "    raw_content = (response.choices[0].message.content or \"\").strip()\n",
    "    # Strip optional ```json fences before parsing\n",
    "    if raw_content.startswith(\"```\"):\n",
    "        raw_content = raw_content[3:].strip()\n",
    "        if raw_content.lower().startswith(\"json\"):\n",
    "            raw_content = raw_content[4:].strip()\n",
    "        if raw_content.endswith(\"```\"):\n",
    "            raw_content = raw_content[:-3].strip()\n",
    "    try:\n",
    "        return json.loads(raw_content)\n",
    "    except Exception:\n",
    "        return {\"links\": []}\n",
    "\n",
    "extractAllRelevantTags(\"https://edwarddonner.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e647b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ecerPFN.cgiPFN.cgiPFN.cgi Jaune\n",
       "## Introduction to Hugging Face\n",
       "Hugging Face is a community-driven platform that enables the collaboration and development of artificial intelligence and machine learning models. The company provides a comprehensive ecosystem for data scientists, developers, and researchers to create, discover, and collaborate on machine learning projects.\n",
       "\n",
       "## Our Mission\n",
       "The mission of Hugging Face is to build the foundation of machine learning tooling with the community, fostering innovation, and facilitating the development of cutting-edge AI models.\n",
       "\n",
       "## Products and Services\n",
       "Hugging Face offers a range of products and services, including:\n",
       "* **Models**: A vast repository of over 1 million models, including state-of-the-art AI models for various applications.\n",
       "* **Datasets**: A collection of over 250,000 datasets, providing access to a wide range of data for machine learning tasks.\n",
       "* **Spaces**: A platform for deploying and running machine learning applications, with over 400,000 applications available.\n",
       "* **Compute**: A paid service offering optimized inference endpoints and GPU deployment options.\n",
       "* **Enterprise**: A suite of solutions for teams and organizations, including single sign-on, priority support, and dedicated resources.\n",
       "\n",
       "## Community and Culture\n",
       "At Hugging Face, we value community and collaboration. Our platform is designed to facilitate the sharing of knowledge, models, and datasets, and to provide a space for developers, researchers, and data scientists to work together. We believe in open-source principles and strive to build a culture of transparency, inclusivity, and innovation.\n",
       "\n",
       "## Customers and Partners\n",
       "Hugging Face has a diverse range of customers and partners, including:\n",
       "* **AI2**: A non-profit organization using Hugging Face for AI research and development.\n",
       "* **Meta**: A technology company leveraging Hugging Face for AI-powered applications.\n",
       "* **Amazon**: A multinational technology company using Hugging Face for machine learning and AI development.\n",
       "* **Google**: A technology leader utilizing Hugging Face for AI research and innovation.\n",
       "* **Intel**: A technology company partnering with Hugging Face for AI-powered solutions.\n",
       "\n",
       "## Careers and Opportunities\n",
       "Hugging Face offers a range of career opportunities for talented individuals in the fields of machine learning, software development, and data science. We are committed to building a diverse and inclusive team, and we encourage applicants from all backgrounds to join our community.\n",
       "\n",
       "## Join Us\n",
       "If you are passionate about artificial intelligence, machine learning, and community-driven development, we invite you to join us. Whether you are a developer, researcher, or simply interested in learning more about Hugging Face, we welcome you to explore our platform, join our community, and contribute to the future of AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Brochure creation part\n",
    "\n",
    "def fetchPageDataAndRelevantLinks(url):\n",
    "    page_content = getContentOfWebPage(url)\n",
    "    relevant_links = extractAllRelevantTags(url)\n",
    "    result = f\"## Landing Page:\\n\\n{page_content}\\n## Relevant Links:\\n\"\n",
    "    links = relevant_links.get(\"links\", []) if isinstance(relevant_links, dict) else []\n",
    "    for link in links:\n",
    "        link_type = link.get(\"type\", \"link\")\n",
    "        link_url = link.get(\"url\")\n",
    "        if not link_url:\n",
    "            continue\n",
    "        result += f\"\\n\\n### Link: {link_type}\\n\"\n",
    "        result += getContentOfWebPage(link_url)\n",
    "    return result\n",
    "\n",
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n",
    "\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetchPageDataAndRelevantLinks(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def generateBrochure(company_name,url):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"llama-3.3-70b-versatile\",\n",
    "        messages = [\n",
    "            {\"role\":\"user\", \"content\":get_brochure_user_prompt(company_name,url)},\n",
    "            {\"role\":\"system\", \"content\": f\"{brochure_system_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    content =  response.choices[0].message.content\n",
    "    return Markdown(content)\n",
    "\n",
    "generateBrochure(company_name=\"Huggingface\", url = \"https://huggingface.co/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eec455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
